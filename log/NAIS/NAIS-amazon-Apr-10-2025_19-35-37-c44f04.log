Thu 10 Apr 2025 19:35:37 INFO  
General Hyper Parameters:
gpu_id = 0
use_gpu = True
seed = 2020
state = INFO
reproducibility = True
data_path = dataset/amazon
checkpoint_dir = ./saved/amazon/
show_progress = True
save_dataset = True
dataset_save_path = None
save_dataloaders = True
dataloaders_save_path = None
log_wandb = False

Training Hyper Parameters:
epochs = 20
train_batch_size = 2048
learner = adam
learning_rate = 0.001
train_neg_sample_args = {'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}
eval_step = 1
stopping_step = 50
clip_grad_norm = None
weight_decay = 0.0
loss_decimal_place = 4

Evaluation Hyper Parameters:
eval_args = {'split': {'RS': [0.8, 0.1, 0.1]}, 'group_by': 'user', 'order': 'RO', 'mode': 'full'}
repeatable = False
metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'MAP', 'Precision', 'GAUC', 'ItemCoverage', 'AveragePopularity', 'GiniIndex', 'ShannonEntropy', 'TailPercentage']
topk = [10]
valid_metric = MRR@10
valid_metric_bigger = True
eval_batch_size = 4096
metric_decimal_place = 4

Dataset Hyper Parameters:
field_separator = 	
seq_separator =  
USER_ID_FIELD = user_id
ITEM_ID_FIELD = item_id
RATING_FIELD = rating
TIME_FIELD = timestamp
seq_len = None
LABEL_FIELD = label
threshold = None
NEG_PREFIX = neg_
load_col = {'inter': ['user_id', 'item_id']}
unload_col = None
unused_col = None
additional_feat_suffix = None
rm_dup_inter = None
val_interval = None
filter_inter_by_user_or_item = True
user_inter_num_interval = [0,inf)
item_inter_num_interval = [0,inf)
alias_of_user_id = None
alias_of_item_id = None
alias_of_entity_id = None
alias_of_relation_id = None
preload_weight = None
normalize_field = None
normalize_all = None
ITEM_LIST_LENGTH_FIELD = item_length
LIST_SUFFIX = _list
MAX_ITEM_LIST_LENGTH = 50
POSITION_FIELD = position_id
HEAD_ENTITY_ID_FIELD = head_id
TAIL_ENTITY_ID_FIELD = tail_id
RELATION_ID_FIELD = relation_id
ENTITY_ID_FIELD = entity_id
benchmark_filename = None

Other Hyper Parameters: 
worker = 0
wandb_project = recbole
shuffle = True
require_pow = False
enable_amp = False
enable_scaler = False
transform = None
algorithm = prod
embedding_size = 64
weight_size = 64
split_to = 0
reg_weights = [1e-07, 1e-07, 1e-05]
alpha = 0.0
beta = 0.5
pretrain_path = None
numerical_features = []
discretization = None
kg_reverse_r = False
entity_kg_num_interval = [0,inf)
relation_kg_num_interval = [0,inf)
MODEL_TYPE = ModelType.GENERAL
MODEL_INPUT_TYPE = InputType.POINTWISE
eval_type = EvaluatorType.RANKING
single_spec = True
local_rank = 0
device = cuda
eval_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}


Thu 10 Apr 2025 19:35:41 INFO  Saving filtered dataset into [./saved/amazon/amazon-dataset.pth]
Thu 10 Apr 2025 19:35:41 INFO  amazon
The number of users: 22156
Average actions of users: 66.16434213495825
The number of items: 54459
Average actions of items: 26.917459326453415
The number of inters: 1465871
The sparsity of the dataset: 99.87851162187994%
Remain Fields: ['user_id', 'item_id']
Thu 10 Apr 2025 19:35:45 INFO  Saving split dataloaders into: [./saved/amazon/amazon-for-NAIS-dataloader.pth]
Thu 10 Apr 2025 19:35:54 INFO  [Training]: train_batch_size = [2048] train_neg_sample_args: [{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]
Thu 10 Apr 2025 19:35:54 INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [0.8, 0.1, 0.1]}, 'group_by': 'user', 'order': 'RO', 'mode': 'full'}]
Thu 10 Apr 2025 19:36:00 WARNING  Pay Attetion!! the `split_to` is set to 0. If you catch a OMM error in this case, you need to increase it 
			until the error disappears. For example, you can append it in the command line such as `--split_to=5`
Thu 10 Apr 2025 19:36:00 INFO  unused pretrain...
Thu 10 Apr 2025 19:36:00 INFO  NAIS(
  (item_src_embedding): Embedding(54459, 64, padding_idx=0)
  (item_dst_embedding): Embedding(54459, 64, padding_idx=0)
  (mlp_layers): MLPLayers(
    (mlp_layers): Sequential(
      (0): Dropout(p=0.0, inplace=False)
      (1): Linear(in_features=64, out_features=64, bias=True)
      (2): ReLU()
    )
  )
  (bceloss): BCEWithLogitsLoss()
)
Trainable parameters: 7029435
Thu 10 Apr 2025 23:07:26 INFO  epoch 0 training [time: 12677.76s, train loss: 500.5812]
